{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from munch import Munch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Munch()\n",
    "\n",
    "opt.dataroot = '../datasets/UIEB_HCLR/'\n",
    "opt.model_path = '../checkpoints/type_extractor/uiebhclr_cc_sc_add_400/100_net_E.pth'\n",
    "\n",
    "opt.mosaic = False\n",
    "opt.mosaic_size = (16, 16)\n",
    "opt.blur = False\n",
    "opt.use_vgg = False\n",
    "opt.adv_norm = 'cc_sc(add)'\n",
    "\n",
    "opt.batch_size = 32\n",
    "opt.num_workers = 8\n",
    "opt.device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianBlur:\n",
    "    def __init__(self, window_size):\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return img.filter(ImageFilter.GaussianBlur(self.window_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mosaic:\n",
    "    def __init__(self, a=16, b=16):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "\n",
    "    def __call__(self, input_tensor):\n",
    "        c, H, W = input_tensor.size()\n",
    "\n",
    "        m, n = H // self.a, W // self.b\n",
    "\n",
    "        input_tensor = input_tensor.view(c, m, self.a, n, self.b)\n",
    "        input_tensor = input_tensor.permute(1, 3, 0, 2, 4).contiguous()\n",
    "        input_tensor = input_tensor.view(m * n, c, self.a, self.b)\n",
    "\n",
    "        indices = torch.randperm(m * n)\n",
    "        input_tensor = input_tensor[indices]\n",
    "\n",
    "        input_tensor = input_tensor.view(m, n, c, self.a, self.b)\n",
    "        input_tensor = input_tensor.permute(2, 0, 3, 1, 4).contiguous()\n",
    "        input_tensor = input_tensor.view(c, H, W)\n",
    "\n",
    "        return input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg\n",
    "\n",
    "class Vgg19(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Vgg19, self).__init__()\n",
    "        self.vgg = vgg.vgg19(weights=vgg.VGG19_Weights.DEFAULT).features\n",
    "        for param in self.vgg.parameters():\n",
    "            param.requires_grad_(False)\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(7*7*512, 1),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, img):\n",
    "        out = self.vgg(img)\n",
    "        out = self.flatten(out)\n",
    "        return self.head(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import functools\n",
    "from models.networks import DownSampleLayer, ResnetBlock, ResnetBlockSC, SCNorm\n",
    "\n",
    "class Extractor(nn.Module):\n",
    "    def __init__(self, norm_layer=nn.InstanceNorm2d, use_dropout=False, ngf=64, padding_type='reflect', adv_norm='cc_sc'):\n",
    "        super(Extractor, self).__init__()\n",
    "        \n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        model = [nn.ReflectionPad2d(3),\n",
    "                 nn.Conv2d(3, ngf, kernel_size=7, padding=0, stride=2, bias=use_bias),\n",
    "                 norm_layer(ngf),\n",
    "                 nn.ReLU(inplace=True),\n",
    "                 nn.MaxPool2d(kernel_size=3, stride=2, padding=1)]\n",
    "        mult = 1\n",
    "        # add ResNet blocks\n",
    "        if adv_norm == '':\n",
    "            model += [\n",
    "                ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout,\n",
    "                            use_bias=use_bias)]\n",
    "        elif 'sc' in adv_norm and 'sc(add)' not in adv_norm:\n",
    "            model += [\n",
    "                ResnetBlockSC(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout,\n",
    "                                use_bias=use_bias)]\n",
    "        elif 'sc(add)' in adv_norm:\n",
    "            model += [\n",
    "                ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout,\n",
    "                            use_bias=use_bias), SCNorm(ngf * mult)]\n",
    "\n",
    "        for _ in range(3):\n",
    "            # add downsample layer\n",
    "            if 'cc' in adv_norm:\n",
    "                if 'cc_' in adv_norm or 'cc(bn)' in adv_norm:\n",
    "                    model.append(DownSampleLayer(ngf * mult, ngf * mult * 2, norm_layer, use_bias, residual_norm='bn'))\n",
    "                elif 'cc(in)' in adv_norm:\n",
    "                    model.append(DownSampleLayer(ngf * mult, ngf * mult * 2, norm_layer, use_bias, residual_norm='in'))\n",
    "            else:\n",
    "                model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1, bias=use_bias),\n",
    "                            norm_layer(ngf * mult * 2),\n",
    "                            nn.ReLU(True)]\n",
    "            mult *= 2\n",
    "\n",
    "            # add ResNet blocks\n",
    "            if adv_norm == '':\n",
    "                model += [\n",
    "                    ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout,\n",
    "                                use_bias=use_bias)]\n",
    "            elif 'sc' in adv_norm and 'sc(add)' not in adv_norm:\n",
    "                model += [\n",
    "                    ResnetBlockSC(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout,\n",
    "                                use_bias=use_bias)]\n",
    "            elif 'sc(add)' in adv_norm:\n",
    "                model += [\n",
    "                    ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout,\n",
    "                                use_bias=use_bias), SCNorm(ngf * mult)]\n",
    "\n",
    "        model.append(nn.AdaptiveAvgPool2d(output_size=(1, 1)))\n",
    "        self.backbone = nn.Sequential(*model)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(512, 1),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.Linear(256, 2)  # 二分类输出\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.backbone(input)\n",
    "        output = self.flatten(output)\n",
    "        return self.head(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet:\n",
    "    IMG_EXTENSIONS = [\n",
    "            '.jpg', '.JPG', '.jpeg', '.JPEG',\n",
    "            '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP',\n",
    "            '.tif', '.TIF', '.tiff', '.TIFF',\n",
    "        ]\n",
    "\n",
    "    def __init__(self, dir_A_list, dir_B_list, opt):\n",
    "        self.dir_A_list = dir_A_list\n",
    "        self.dir_B_list = dir_B_list\n",
    "        self.opt = opt\n",
    "\n",
    "        self.paths_A = []\n",
    "        for dir_A in self.dir_A_list:\n",
    "            self.paths_A += sorted(self.make_dataset(dir_A))\n",
    "        self.paths_B = []\n",
    "        for dir_B in self.dir_B_list:\n",
    "            self.paths_B += sorted(self.make_dataset(dir_B))\n",
    "        self.num_A = len(self.paths_A)\n",
    "        self.paths = self.paths_A + self.paths_B\n",
    "        if not opt.use_vgg:\n",
    "            img_size = 256\n",
    "            mean = (0.5, 0.5, 0.5)\n",
    "            std = (0.5, 0.5, 0.5)\n",
    "        else:\n",
    "            img_size = 224\n",
    "            mean = (0.485, 0.456, 0.406)\n",
    "            std = (0.229, 0.224, 0.225)\n",
    "        transform_list = [\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ]\n",
    "        if opt.blur:\n",
    "            transform_list.insert(1, GaussianBlur(img_size))\n",
    "        if opt.mosaic:\n",
    "            transform_list.append(Mosaic(*opt.mosaic_size))\n",
    "        self.transform = transforms.Compose(transform_list)\n",
    "\n",
    "    @classmethod\n",
    "    def is_image_file(cls, filename):\n",
    "        return any(filename.endswith(extension) for extension in cls.IMG_EXTENSIONS)\n",
    "\n",
    "    def make_dataset(self, dir):\n",
    "        images = []\n",
    "        assert os.path.isdir(dir), '%s is not a valid directory' % dir\n",
    "        for root, _, fnames in sorted(os.walk(dir)):\n",
    "            for fname in fnames:\n",
    "                if self.is_image_file(fname):\n",
    "                    path = os.path.join(root, fname)\n",
    "                    images.append(path)\n",
    "        return images\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.paths[index]\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        if index < self.num_A:\n",
    "            label = 0\n",
    "        else:\n",
    "            label = 1\n",
    "\n",
    "        return {'img': self.transform(img), 'label': label, 'path': path}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Classifier()\n",
    "\n",
    "if not opt.use_vgg:\n",
    "    model = Extractor(adv_norm=opt.adv_norm)\n",
    "else:\n",
    "    model = Vgg19()\n",
    "model.load_state_dict(torch.load(opt.model_path))\n",
    "model = model.to(opt.device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n"
     ]
    }
   ],
   "source": [
    "dataset = DataSet([os.path.join(opt.dataroot, 'testA')], [os.path.join(opt.dataroot, 'testB_gt')], opt=opt)\n",
    "dataloader = DataLoader(dataset, batch_size=opt.batch_size, shuffle=True, num_workers=opt.num_workers)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = 0\n",
    "total_samples = 0\n",
    "with torch.no_grad():\n",
    "    for data in dataloader:\n",
    "        imgs, labels = data['img'].to(opt.device), data['label'].to(opt.device)\n",
    "        outs = model(imgs)\n",
    "        # _, predicted = torch.max(outs, dim=1)\n",
    "        predicted = outs.ge(0.5).squeeze()\n",
    "\n",
    "        for item in zip(data['path'], data['label'].tolist(), predicted.tolist()):\n",
    "            if item[1] != item[2]:\n",
    "                print(item)\n",
    "\n",
    "        total_samples += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
