{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78ef2905-4223-47ce-ba53-27fe64ddb35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from munch import Munch\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, models\n",
    "# from torch.nn.functional import one_hot\n",
    "from PIL import Image, ImageFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cae10c1-98fb-44b9-98b4-a64970985c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Munch()\n",
    "\n",
    "opt.dataroot = '../datasets/UIEB/'\n",
    "opt.adv_norm = 'cc_sc(add)'\n",
    "opt.mosaic = False\n",
    "opt.mosaic_size = (16, 16)\n",
    "opt.blur = False\n",
    "opt.use_vgg = False\n",
    "opt.save_dir = '../checkpoints/type_extractor/uieb'\n",
    "\n",
    "opt.n_epochs = 5\n",
    "opt.n_epochs_decay = 10\n",
    "\n",
    "opt.lr = 0.0002\n",
    "opt.batch_size = 32\n",
    "\n",
    "opt.print_freq = 10\n",
    "opt.save_freq = 100\n",
    "opt.verify_freq = 10\n",
    "\n",
    "opt.num_workers = 8\n",
    "opt.device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "opt.log_file_path = os.path.join(opt.save_dir, 'log.txt')\n",
    "\n",
    "if not os.path.exists(opt.save_dir):\n",
    "    os.makedirs(opt.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00964009",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianBlur:\n",
    "    def __init__(self, window_size):\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return img.filter(ImageFilter.GaussianBlur(self.window_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70111d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mosaic:\n",
    "    def __init__(self, a=16, b=16):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "\n",
    "    def __call__(self, input_tensor):\n",
    "        c, H, W = input_tensor.size()\n",
    "\n",
    "        m, n = H // self.a, W // self.b\n",
    "\n",
    "        input_tensor = input_tensor.view(c, m, self.a, n, self.b)\n",
    "        input_tensor = input_tensor.permute(1, 3, 0, 2, 4).contiguous()\n",
    "        input_tensor = input_tensor.view(m * n, c, self.a, self.b)\n",
    "\n",
    "        indices = torch.randperm(m * n)\n",
    "        input_tensor = input_tensor[indices]\n",
    "\n",
    "        input_tensor = input_tensor.view(m, n, c, self.a, self.b)\n",
    "        input_tensor = input_tensor.permute(2, 0, 3, 1, 4).contiguous()\n",
    "        input_tensor = input_tensor.view(c, H, W)\n",
    "\n",
    "\n",
    "        return input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fd4b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log:\n",
    "    def __init__(self, log_file_path):\n",
    "        self.log_file = open(log_file_path, 'a', encoding='utf-8')\n",
    "        \n",
    "        self.print(str(datetime.now()) + '\\n')\n",
    "        for key, value in opt.items():\n",
    "            self.print(f\"{key} = {value}\")\n",
    "\n",
    "    def print(self, message):\n",
    "        print(message)\n",
    "        self.log_file.write(message + '\\n')\n",
    "\n",
    "    def __del__(self):\n",
    "        self.log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5e8a955",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg\n",
    "\n",
    "class Vgg19(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Vgg19, self).__init__()\n",
    "        self.vgg = vgg.vgg19(weights=vgg.VGG19_Weights.DEFAULT).features\n",
    "        for param in self.vgg.parameters():\n",
    "            param.requires_grad_(False)\n",
    "        # self.linear = nn.Sequential(nn.Linear(7*7*512, 4096),\n",
    "        #                             nn.ReLU(inplace=True),\n",
    "        #                             nn.Linear(4096, 512))\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(7*7*512, 1),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, img):\n",
    "        out = self.vgg(img)\n",
    "        out = self.flatten(out)\n",
    "        # out = self.linear(out)\n",
    "        return self.head(out)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272a497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import functools\n",
    "from models.networks import DownSampleLayer, ResnetBlock, ResnetBlockSC, SCNorm\n",
    "\n",
    "class Extractor(nn.Module):\n",
    "    def __init__(self, norm_layer=nn.InstanceNorm2d, use_dropout=False, ngf=64, padding_type='reflect', adv_norm='cc_sc'):\n",
    "        super(Extractor, self).__init__()\n",
    "        \n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        model = [nn.ReflectionPad2d(3),\n",
    "                 nn.Conv2d(3, ngf, kernel_size=7, padding=0, stride=2, bias=use_bias),\n",
    "                 norm_layer(ngf),\n",
    "                 nn.ReLU(inplace=True),\n",
    "                 nn.MaxPool2d(kernel_size=3, stride=2, padding=1)]\n",
    "        mult = 1\n",
    "        # add ResNet blocks\n",
    "        if adv_norm == '':\n",
    "            model += [\n",
    "                ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout,\n",
    "                            use_bias=use_bias)]\n",
    "        elif 'sc' in adv_norm and 'sc(add)' not in adv_norm:\n",
    "            model += [\n",
    "                ResnetBlockSC(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout,\n",
    "                                use_bias=use_bias)]\n",
    "        elif 'sc(add)' in adv_norm:\n",
    "            model += [\n",
    "                ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout,\n",
    "                            use_bias=use_bias), SCNorm(ngf * mult)]\n",
    "\n",
    "        for _ in range(3):\n",
    "            # add downsample layer\n",
    "            if 'cc' in adv_norm:\n",
    "                if 'cc_' in adv_norm or 'cc(bn)' in adv_norm:\n",
    "                    model.append(DownSampleLayer(ngf * mult, ngf * mult * 2, norm_layer, use_bias, residual_norm='bn'))\n",
    "                elif 'cc(in)' in adv_norm:\n",
    "                    model.append(DownSampleLayer(ngf * mult, ngf * mult * 2, norm_layer, use_bias, residual_norm='in'))\n",
    "            else:\n",
    "                model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1, bias=use_bias),\n",
    "                            norm_layer(ngf * mult * 2),\n",
    "                            nn.ReLU(True)]\n",
    "            mult *= 2\n",
    "\n",
    "            # add ResNet blocks\n",
    "            if adv_norm == '':\n",
    "                model += [\n",
    "                    ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout,\n",
    "                                use_bias=use_bias)]\n",
    "            elif 'sc' in adv_norm and 'sc(add)' not in adv_norm:\n",
    "                model += [\n",
    "                    ResnetBlockSC(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout,\n",
    "                                use_bias=use_bias)]\n",
    "            elif 'sc(add)' in adv_norm:\n",
    "                model += [\n",
    "                    ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout,\n",
    "                                use_bias=use_bias), SCNorm(ngf * mult)]\n",
    "\n",
    "        model.append(nn.AdaptiveAvgPool2d(output_size=(1, 1)))\n",
    "        self.backbone = nn.Sequential(*model)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.backbone(input)\n",
    "        output = self.flatten(output)\n",
    "        return self.head(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dedff34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(net, init_type='normal', init_gain=0.02):\n",
    "    \"\"\"Initialize network weights.\n",
    "\n",
    "    Parameters:\n",
    "        net (network)   -- network to be initialized\n",
    "        init_type (str) -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n",
    "        init_gain (float)    -- scaling factor for normal, xavier and orthogonal.\n",
    "\n",
    "    We use 'normal' in the original pix2pix and CycleGAN paper. But xavier and kaiming might\n",
    "    work better for some applications. Feel free to try yourself.\n",
    "    \"\"\"\n",
    "\n",
    "    def init_func(m):  # define the initialization function\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "            if init_type == 'normal':\n",
    "                nn.init.normal_(m.weight.data, 0.0, init_gain)\n",
    "            elif init_type == 'xavier':\n",
    "                nn.init.xavier_normal_(m.weight.data, gain=init_gain)\n",
    "            elif init_type == 'kaiming':\n",
    "                nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "            elif init_type == 'orthogonal':\n",
    "                nn.init.orthogonal_(m.weight.data, gain=init_gain)\n",
    "            else:\n",
    "                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                nn.init.constant_(m.bias.data, 0.0)\n",
    "        elif classname.find(\n",
    "                'BatchNorm2d') != -1:  # BatchNorm Layer's weight is not a matrix; only normal distribution applies.\n",
    "            nn.init.normal_(m.weight.data, 1.0, init_gain)\n",
    "            nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "    print('initialize network with %s' % init_type)\n",
    "    net.apply(init_func)  # apply the initialization function <init_func>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2988d267-9637-4acd-95a4-54d733e2b1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet:\n",
    "    IMG_EXTENSIONS = [\n",
    "            '.jpg', '.JPG', '.jpeg', '.JPEG',\n",
    "            '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP',\n",
    "            '.tif', '.TIF', '.tiff', '.TIFF',\n",
    "        ]\n",
    "\n",
    "    def __init__(self, dir_A_list, dir_B_list, opt):\n",
    "        self.dir_A_list = dir_A_list\n",
    "        self.dir_B_list = dir_B_list\n",
    "        self.opt = opt\n",
    "\n",
    "        self.paths_A = []\n",
    "        for dir_A in self.dir_A_list:\n",
    "            self.paths_A += sorted(self.make_dataset(dir_A))\n",
    "        self.paths_B = []\n",
    "        for dir_B in self.dir_B_list:\n",
    "            self.paths_B += sorted(self.make_dataset(dir_B))\n",
    "        self.num_A = len(self.paths_A)\n",
    "        self.paths = self.paths_A + self.paths_B\n",
    "        if not opt.use_vgg:\n",
    "            img_size = 256\n",
    "            mean = (0.5, 0.5, 0.5)\n",
    "            std = (0.5, 0.5, 0.5)\n",
    "        else:\n",
    "            img_size = 224\n",
    "            mean = (0.485, 0.456, 0.406)\n",
    "            std = (0.229, 0.224, 0.225)\n",
    "        transform_list = [\n",
    "            transforms.RandomResizedCrop(img_size, scale=(0.7, 1.0)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ]\n",
    "        if opt.blur:\n",
    "            transform_list.insert(2, GaussianBlur(img_size))\n",
    "        if opt.mosaic:\n",
    "            transform_list.append(Mosaic(*opt.mosaic_size))\n",
    "        self.transform = transforms.Compose(transform_list)\n",
    "\n",
    "    @classmethod\n",
    "    def is_image_file(cls, filename):\n",
    "        return any(filename.endswith(extension) for extension in cls.IMG_EXTENSIONS)\n",
    "\n",
    "    def make_dataset(self, dir):\n",
    "        images = []\n",
    "        assert os.path.isdir(dir), '%s is not a valid directory' % dir\n",
    "        for root, _, fnames in sorted(os.walk(dir)):\n",
    "            for fname in fnames:\n",
    "                if self.is_image_file(fname):\n",
    "                    path = os.path.join(root, fname)\n",
    "                    images.append(path)\n",
    "        return images\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.paths[index]\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        if index < self.num_A:\n",
    "            label = 0\n",
    "        else:\n",
    "            label = 1\n",
    "\n",
    "        return {'img': self.transform(img), 'label': label, 'path': path}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0038479-2008-481b-ba29-4a9e610888d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_rule(epoch):\n",
    "    lamda = 1.0 - max(0, epoch - opt.n_epochs) / float(opt.n_epochs_decay + 1)\n",
    "    return lamda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0243e3e3-dd61-4db0-9902-057bac7553f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = Log(opt.log_file_path)\n",
    "\n",
    "if not opt.use_vgg:\n",
    "    model = Extractor()\n",
    "    model.to(opt.device)\n",
    "    init_weights(model)\n",
    "else:\n",
    "    model = Vgg19()\n",
    "    model.to(opt.device)\n",
    "    nn.init.normal_(model.head[0].weight.data, 0.0, 0.02)\n",
    "    nn.init.constant_(model.head[0].bias.data, 0.0)\n",
    "\n",
    "num_params = 0\n",
    "for param in model.parameters():\n",
    "    num_params += param.numel()\n",
    "log.print('Total number of parameters : %.3f M' % (num_params / 1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c956861-5c2e-4e1a-9c1f-28135462d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataSet([os.path.join(opt.dataroot, 'trainA')], [os.path.join(opt.dataroot, 'trainB')], opt)\n",
    "dataset_verify = DataSet([os.path.join(opt.dataroot, 'valA')], [os.path.join(opt.dataroot, 'valB_gt')], opt)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=opt.batch_size, shuffle=True, num_workers=opt.num_workers)\n",
    "dataloader_verify = DataLoader(dataset_verify, batch_size=opt.batch_size, shuffle=True, num_workers=opt.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fc39bdb-b518-44bf-b24a-0daebefb80dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ed9387b-c42e-4017-a354-3a2c91e9d744",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=opt.lr)\n",
    "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8f5c57-44b4-4968-9a49-7a05c62a1617",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, opt.n_epochs + opt.n_epochs_decay + 1):\n",
    "    total_iters = 0\n",
    "    model.train()\n",
    "    epoch_start = time.time()\n",
    "    iter_data_time = time.time()\n",
    "    for total_iters, data in enumerate(dataloader, 1):\n",
    "        iter_start_time = time.time()\n",
    "        if total_iters % opt.print_freq == 0:\n",
    "            t_data = iter_start_time - iter_data_time\n",
    "        imgs, labels = data['img'].to(opt.device), data['label'].to(opt.device)\n",
    "        outs = model(imgs)\n",
    "        # loss = criterion(outs, one_hot(labels, num_classes=2).float())\n",
    "        loss = criterion(outs.squeeze(), labels.float())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        t_comp = time.time() - iter_start_time\n",
    "        if total_iters % opt.print_freq == 0:\n",
    "            log.print(f\"epoch: {epoch}, iters: {total_iters}, time: {t_comp:.6f}, data: {t_data:.6f}, loss: {loss.item():.6f}\")\n",
    "        iter_data_time = time.time()\n",
    "    \n",
    "    log.print(f\"End of epoch {epoch} / {opt.n_epochs + opt.n_epochs_decay} Time taken: {time.time() - epoch_start:.6f} sec\")\n",
    "    old_lr = scheduler.get_last_lr()\n",
    "    scheduler.step()\n",
    "    log.print(f\"learning rate: {old_lr[0]:.6f} -> {scheduler.get_last_lr()[0]:.6f}\")\n",
    "    if epoch % opt.save_freq == 0:\n",
    "        print(f\"saving the model at the end of epoch: {epoch}\")\n",
    "        if not os.path.exists(opt.save_dir):\n",
    "            os.makedirs(opt.save_dir)\n",
    "        torch.save(model.state_dict(), os.path.join(opt.save_dir, f\"{epoch}_net_E.pth\"))\n",
    "    if epoch % opt.verify_freq == 0:\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data in dataloader_verify:\n",
    "                imgs, labels = data['img'].to(opt.device), data['label'].to(opt.device)\n",
    "                outs = model(imgs)\n",
    "                # _, predicted = torch.max(outs, dim=1)\n",
    "                predicted = outs.ge(0.5).squeeze()\n",
    "                total_samples += labels.size(0)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "            accuracy = correct_predictions / total_samples\n",
    "            log.print(f'Validation Accuracy: {accuracy * 100:.2f}%')\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e884c7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "del log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eec21f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
